{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f87861cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cea0d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.1+cu117', True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5795f32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(56, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a31bc962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_pic_embeddings_resnet_v1</th>\n",
       "      <th>name_bert_64</th>\n",
       "      <th>color_parsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variantid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51195767</th>\n",
       "      <td>[[0.04603629, 0.18839523, -0.09973055, -0.6636...</td>\n",
       "      <td>[-0.47045058, 0.67237014, 0.48984158, -0.54485...</td>\n",
       "      <td>[оранжевый]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53565809</th>\n",
       "      <td>[[1.1471839, -0.665361, 0.7745614, 0.26716197,...</td>\n",
       "      <td>[-0.6575592, 0.6522429, 0.5426037, -0.54347897...</td>\n",
       "      <td>[красный]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56763357</th>\n",
       "      <td>[[-0.90570974, 1.0296293, 1.0769907, 0.27746, ...</td>\n",
       "      <td>[-0.7384308, 0.70784587, 0.3012653, -0.3583719...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56961772</th>\n",
       "      <td>[[0.13133773, -0.5577079, 0.32498044, 0.191717...</td>\n",
       "      <td>[-0.44812852, 0.5283565, 0.28981736, -0.506841...</td>\n",
       "      <td>[черный]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61054740</th>\n",
       "      <td>[[0.21696381, 0.10989461, -0.08012986, 0.69186...</td>\n",
       "      <td>[-0.72692573, 0.75206333, 0.37740713, -0.52502...</td>\n",
       "      <td>[черный]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820128810</th>\n",
       "      <td>[[-1.4492652, -0.80129164, -0.12344764, 0.7194...</td>\n",
       "      <td>[-0.8253241, 0.6785133, 0.53978086, -0.4888316...</td>\n",
       "      <td>[пурпурный]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821135769</th>\n",
       "      <td>[[0.012127608, -0.8534423, 0.5415518, -0.44912...</td>\n",
       "      <td>[-0.7413257, 0.46105132, 0.5639801, -0.5462132...</td>\n",
       "      <td>[черный]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822095690</th>\n",
       "      <td>[[0.4248176, -0.15944786, -0.22844064, 0.42768...</td>\n",
       "      <td>[-0.49261805, 0.56726897, 0.7037877, -0.697246...</td>\n",
       "      <td>[черный]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822101044</th>\n",
       "      <td>[[0.4248176, -0.15944786, -0.22844064, 0.42768...</td>\n",
       "      <td>[-0.44051006, 0.54029673, 0.63768685, -0.68040...</td>\n",
       "      <td>[черный]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822394794</th>\n",
       "      <td>[[0.48594046, -0.8139478, -0.11380915, -0.3833...</td>\n",
       "      <td>[-0.56425023, 0.41288334, 0.5501014, -0.330675...</td>\n",
       "      <td>[grey, серый]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               main_pic_embeddings_resnet_v1  \\\n",
       "variantid                                                      \n",
       "51195767   [[0.04603629, 0.18839523, -0.09973055, -0.6636...   \n",
       "53565809   [[1.1471839, -0.665361, 0.7745614, 0.26716197,...   \n",
       "56763357   [[-0.90570974, 1.0296293, 1.0769907, 0.27746, ...   \n",
       "56961772   [[0.13133773, -0.5577079, 0.32498044, 0.191717...   \n",
       "61054740   [[0.21696381, 0.10989461, -0.08012986, 0.69186...   \n",
       "...                                                      ...   \n",
       "820128810  [[-1.4492652, -0.80129164, -0.12344764, 0.7194...   \n",
       "821135769  [[0.012127608, -0.8534423, 0.5415518, -0.44912...   \n",
       "822095690  [[0.4248176, -0.15944786, -0.22844064, 0.42768...   \n",
       "822101044  [[0.4248176, -0.15944786, -0.22844064, 0.42768...   \n",
       "822394794  [[0.48594046, -0.8139478, -0.11380915, -0.3833...   \n",
       "\n",
       "                                                name_bert_64   color_parsed  \n",
       "variantid                                                                    \n",
       "51195767   [-0.47045058, 0.67237014, 0.48984158, -0.54485...    [оранжевый]  \n",
       "53565809   [-0.6575592, 0.6522429, 0.5426037, -0.54347897...      [красный]  \n",
       "56763357   [-0.7384308, 0.70784587, 0.3012653, -0.3583719...           None  \n",
       "56961772   [-0.44812852, 0.5283565, 0.28981736, -0.506841...       [черный]  \n",
       "61054740   [-0.72692573, 0.75206333, 0.37740713, -0.52502...       [черный]  \n",
       "...                                                      ...            ...  \n",
       "820128810  [-0.8253241, 0.6785133, 0.53978086, -0.4888316...    [пурпурный]  \n",
       "821135769  [-0.7413257, 0.46105132, 0.5639801, -0.5462132...       [черный]  \n",
       "822095690  [-0.49261805, 0.56726897, 0.7037877, -0.697246...       [черный]  \n",
       "822101044  [-0.44051006, 0.54029673, 0.63768685, -0.68040...       [черный]  \n",
       "822394794  [-0.56425023, 0.41288334, 0.5501014, -0.330675...  [grey, серый]  \n",
       "\n",
       "[457063 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['variantid', 'main_pic_embeddings_resnet_v1', 'name_bert_64', 'color_parsed']\n",
    "train_data = pd.read_parquet('./datasets/train_data.parquet', columns=columns).set_index('variantid')\n",
    "test_data = pd.read_parquet('./datasets/test_data.parquet', columns=columns).set_index('variantid')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0cabc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>variantid1</th>\n",
       "      <th>variantid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51197862</td>\n",
       "      <td>51198054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53062686</td>\n",
       "      <td>536165289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>53602615</td>\n",
       "      <td>587809782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>53888651</td>\n",
       "      <td>89598677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>56930698</td>\n",
       "      <td>551526166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306535</th>\n",
       "      <td>0</td>\n",
       "      <td>817327230</td>\n",
       "      <td>822083612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306536</th>\n",
       "      <td>0</td>\n",
       "      <td>817560551</td>\n",
       "      <td>818069912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306537</th>\n",
       "      <td>0</td>\n",
       "      <td>817854719</td>\n",
       "      <td>817857267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306538</th>\n",
       "      <td>0</td>\n",
       "      <td>820036017</td>\n",
       "      <td>820037019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306539</th>\n",
       "      <td>0</td>\n",
       "      <td>821514120</td>\n",
       "      <td>821514311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306540 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target  variantid1  variantid2\n",
       "0            0    51197862    51198054\n",
       "1            1    53062686   536165289\n",
       "2            1    53602615   587809782\n",
       "3            1    53888651    89598677\n",
       "4            0    56930698   551526166\n",
       "...        ...         ...         ...\n",
       "306535       0   817327230   822083612\n",
       "306536       0   817560551   818069912\n",
       "306537       0   817854719   817857267\n",
       "306538       0   820036017   820037019\n",
       "306539       0   821514120   821514311\n",
       "\n",
       "[306540 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs = pd.read_parquet('./datasets/train_pairs_w_target.parquet')\n",
    "test_pairs = pd.read_parquet('./datasets/test_pairs_wo_target.parquet')\n",
    "train_pairs['target'] = train_pairs['target'].astype(int)\n",
    "train_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e9967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf4a585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_labse_768</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variantid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51195767</th>\n",
       "      <td>[-0.033874325, 0.03722446, 0.0029757991, 0.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53565809</th>\n",
       "      <td>[0.015568526, -0.03899538, 0.064447366, 0.0383...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56763357</th>\n",
       "      <td>[-0.033072222, -0.04237577, 0.020771954, 0.065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56961772</th>\n",
       "      <td>[0.014727573, -0.025661988, 0.023943473, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61054740</th>\n",
       "      <td>[0.043145332, -0.052424084, 0.017260496, 0.045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820128810</th>\n",
       "      <td>[-0.003678058, -0.031628493, 0.0065589263, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821135769</th>\n",
       "      <td>[-0.06858361, 0.027011767, -0.016400583, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822095690</th>\n",
       "      <td>[-0.04474233, -0.034224413, 0.026076552, 0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822101044</th>\n",
       "      <td>[-0.05541598, 0.000863006, 0.01093415, 0.02208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822394794</th>\n",
       "      <td>[-0.024839332, -0.010900456, 0.035838403, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457063 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name_labse_768\n",
       "variantid                                                   \n",
       "51195767   [-0.033874325, 0.03722446, 0.0029757991, 0.068...\n",
       "53565809   [0.015568526, -0.03899538, 0.064447366, 0.0383...\n",
       "56763357   [-0.033072222, -0.04237577, 0.020771954, 0.065...\n",
       "56961772   [0.014727573, -0.025661988, 0.023943473, -0.00...\n",
       "61054740   [0.043145332, -0.052424084, 0.017260496, 0.045...\n",
       "...                                                      ...\n",
       "820128810  [-0.003678058, -0.031628493, 0.0065589263, 0.0...\n",
       "821135769  [-0.06858361, 0.027011767, -0.016400583, -0.02...\n",
       "822095690  [-0.04474233, -0.034224413, 0.026076552, 0.026...\n",
       "822101044  [-0.05541598, 0.000863006, 0.01093415, 0.02208...\n",
       "822394794  [-0.024839332, -0.010900456, 0.035838403, -0.0...\n",
       "\n",
       "[457063 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_labse_embs = pd.read_parquet('F:/name_labse_embs.parquet').set_index('variantid')\n",
    "name_labse_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bd441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e5ad411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_vocab = {}\n",
    "cur_id = 1\n",
    "max_count = 0\n",
    "for colors in np.concatenate([train_data['color_parsed'], test_data['color_parsed']]):\n",
    "    if colors is None:\n",
    "        continue\n",
    "    max_count = max(max_count, len(colors))\n",
    "    for value in colors:\n",
    "        if value not in color_vocab:\n",
    "            color_vocab[value] = cur_id\n",
    "            cur_id += 1\n",
    "cur_id, max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b5fb0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variantid\n",
       "51195767     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "53565809     [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "56763357     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "56961772     [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "61054740     [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                                   ...                        \n",
       "820128810    [16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "821135769    [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "822095690    [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "822101044    [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "822394794    [27, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "Name: color_parsed, Length: 457063, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def color_to_idx(colors):\n",
    "    if colors is None:\n",
    "        return []\n",
    "    return [color_vocab[color] for color in colors]\n",
    "\n",
    "def pad_colors(colors):\n",
    "    max_len = 20\n",
    "    if len(colors) > max_len:\n",
    "        return colors[:max_len]\n",
    "    return colors + [0] * (max_len - len(colors))\n",
    "\n",
    "train_data['color_parsed'] = train_data['color_parsed'].apply(color_to_idx).apply(pad_colors)\n",
    "test_data['color_parsed'] = test_data['color_parsed'].apply(color_to_idx).apply(pad_colors)\n",
    "train_data['color_parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b7f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c912ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_pairs, val_pairs = train_test_split(train_pairs, test_size=1/3, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0d047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "148eb804",
   "metadata": {},
   "source": [
    "# говнокод, потом красивее сделаю\n",
    "\n",
    "pairs = {}\n",
    "for target, v, u in zip(train_pairs.target, train_pairs.variantid1, train_pairs.variantid2):\n",
    "    if not target:\n",
    "        continue\n",
    "    if v not in pairs:\n",
    "        pairs[v] = {}\n",
    "    if u not in pairs:\n",
    "        pairs[u] = {}\n",
    "        \n",
    "    pairs[v][u] = pairs[u][v] = 1\n",
    "    \n",
    "new_pairs = set()\n",
    "for b in tqdm(pairs):\n",
    "    for a in pairs[b]:\n",
    "        for c in pairs[b]:\n",
    "            if a >= c:\n",
    "                continue\n",
    "            if pairs.get(a, {}).get(c, -1) != 1 and pairs.get(c, {}).get(a, -1) != 1:   \n",
    "                new_pairs.add((a, c))\n",
    "                \n",
    "print(len(new_pairs))\n",
    "\n",
    "tmp = []\n",
    "for a, c in new_pairs:\n",
    "    tmp.append({\n",
    "        'target': 1,\n",
    "        'variantid1': a,\n",
    "        'variantid2': c\n",
    "    })\n",
    "train_pairs = pd.concat([train_pairs, pd.DataFrame(tmp)])\n",
    "train_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338365bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c25370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 128\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8955f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemsDataset(Dataset):\n",
    "    def __init__(self, pairs, data):\n",
    "        super().__init__()\n",
    "        self.pairs = pairs.values\n",
    "        self.main_pic_embs = data['main_pic_embeddings_resnet_v1']\n",
    "        self.name_embs = data['name_bert_64']\n",
    "        self.name_labse_embs = name_labse_embs['name_labse_768']\n",
    "        self.colors = data['color_parsed']\n",
    "        self.pairs_len = len(self.pairs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.pairs_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target, id1, id2 = self.pairs[idx, :]\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(np.concatenate([self.main_pic_embs[id1][0], self.name_embs[id1], self.name_labse_embs[id1]])),\n",
    "            torch.tensor(self.colors[id1]),\n",
    "            torch.tensor(np.concatenate([self.main_pic_embs[id2][0], self.name_embs[id2], self.name_labse_embs[id2]])),\n",
    "            torch.tensor(self.colors[id2]),\n",
    "            torch.tensor(target)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e40e3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(pairs, data, batch_size, drop_last, shuffle):\n",
    "    dataset = ItemsDataset(pairs, data)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=drop_last,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e1ef7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(args):\n",
    "    train_loader = get_data_loader(\n",
    "        pairs=train_pairs,\n",
    "        data=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader = get_data_loader(\n",
    "        pairs=val_pairs,\n",
    "        data=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=False,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c6d7ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 799)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader = get_loaders(args)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f78907fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7913, -0.3410, -1.1740,  ...,  0.0648, -0.0277,  0.0173],\n",
      "        [-0.4890,  0.0393, -1.2099,  ...,  0.0233, -0.0398, -0.0351],\n",
      "        [-1.1650,  0.4374, -0.0684,  ..., -0.0366, -0.0449,  0.0196],\n",
      "        ...,\n",
      "        [ 0.2943, -0.0427, -0.0534,  ..., -0.0074, -0.0324, -0.0109],\n",
      "        [-0.1379,  0.2678,  0.6704,  ..., -0.0098,  0.0305,  0.0413],\n",
      "        [ 0.5079, -0.5721, -0.9554,  ...,  0.0431, -0.0601, -0.0029]]) tensor([[ 6,  0,  0,  ...,  0,  0,  0],\n",
      "        [35,  9,  7,  ...,  0,  0,  0],\n",
      "        [ 3,  0,  0,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 7,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 3,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 3,  0,  0,  ...,  0,  0,  0]]) tensor([[ 0.8538, -0.2273, -1.1336,  ...,  0.0446, -0.0332,  0.0080],\n",
      "        [-0.5894,  0.0583, -1.1590,  ...,  0.0236,  0.0097, -0.0238],\n",
      "        [-1.7001,  0.2358, -0.2245,  ..., -0.0366, -0.0426,  0.0158],\n",
      "        ...,\n",
      "        [ 0.1755,  0.4481, -0.1310,  ..., -0.0074, -0.0324, -0.0109],\n",
      "        [-0.4031, -0.0769,  0.4919,  ..., -0.0098,  0.0305,  0.0413],\n",
      "        [ 0.3412, -0.6184, -1.0135,  ...,  0.0301, -0.0642,  0.0115]]) tensor([[17,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 7,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 7,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 3,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 8,  3,  7,  ...,  0,  0,  0]]) tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for x1, colors1, x2, colors2, target in train_loader:\n",
    "    print(x1, colors1, x2, colors2, target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "163cd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data, a=0, mode=\"fan_in\")\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data, a=0, mode=\"fan_out\")\n",
    "    elif classname.find(\"BatchNorm1d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "    if hasattr(m, \"bias\") and m.bias is not None:\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Linear\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, std=0.001)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class ClassBlock(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, class_num, droprate, relu=False, bnorm=True, linear=512\n",
    "    ):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        add_block = []\n",
    "        if linear > 0:\n",
    "            add_block += [torch.nn.Linear(input_dim, linear)]\n",
    "        else:\n",
    "            linear = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [torch.nn.BatchNorm1d(linear)]\n",
    "        if relu:\n",
    "            add_block += [torch.nn.LeakyReLU(0.1)]\n",
    "        if droprate > 0:\n",
    "            add_block += [torch.nn.Dropout(p=droprate)]\n",
    "        add_block = torch.nn.Sequential(*add_block)\n",
    "        add_block.apply(weights_init_kaiming)\n",
    "\n",
    "        classifier = torch.nn.Linear(linear, class_num)\n",
    "        classifier.apply(weights_init_classifier)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.add_block(x)\n",
    "        output = self.classifier(features)\n",
    "        return features, self.sigmoid(output).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df38bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/TinyZeaMays/CircleLoss/blob/master/circle_loss.py\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "\n",
    "def convert_label_to_similarity(normed_feature: Tensor, label: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    similarity_matrix = normed_feature @ normed_feature.transpose(1, 0)\n",
    "    label_matrix = label.unsqueeze(1) == label.unsqueeze(0)\n",
    "\n",
    "    positive_matrix = label_matrix.triu(diagonal=1)\n",
    "    negative_matrix = label_matrix.logical_not().triu(diagonal=1)\n",
    "\n",
    "    similarity_matrix = similarity_matrix.view(-1)\n",
    "    positive_matrix = positive_matrix.view(-1)\n",
    "    negative_matrix = negative_matrix.view(-1)\n",
    "    return similarity_matrix[positive_matrix], similarity_matrix[negative_matrix]\n",
    "\n",
    "\n",
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, m: float, gamma: float) -> None:\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.m = m\n",
    "        self.gamma = gamma\n",
    "        self.soft_plus = nn.Softplus()\n",
    "\n",
    "    def forward(self, sp: Tensor, sn: Tensor) -> Tensor:\n",
    "        ap = torch.clamp_min(-sp.detach() + 1 + self.m, min=0.0)\n",
    "        an = torch.clamp_min(sn.detach() + self.m, min=0.0)\n",
    "\n",
    "        delta_p = 1 - self.m\n",
    "        delta_n = self.m\n",
    "\n",
    "        logit_p = -ap * (sp - delta_p) * self.gamma\n",
    "        logit_n = an * (sn - delta_n) * self.gamma\n",
    "\n",
    "        loss = self.soft_plus(torch.logsumexp(logit_n, dim=0) + torch.logsumexp(logit_p, dim=0))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b84d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses\n",
    "\n",
    "class ReIdentificationLossWithClassification(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.CircleLoss = CircleLoss(m=0.25, gamma=64)\n",
    "        self.CrossEntropyLoss = nn.BCELoss()\n",
    "        self.ContrastLoss = losses.ContrastiveLoss(pos_margin=0, neg_margin=1)\n",
    "\n",
    "    def forward(self, features, logits, labels):\n",
    "        BS = labels.shape[0]\n",
    "\n",
    "        fnorm = torch.norm(features, p=2, dim=1, keepdim=True)\n",
    "        features = features.div(fnorm.expand_as(features))\n",
    "\n",
    "        ce_loss = self.CrossEntropyLoss(logits, labels)\n",
    "        contrast_loss = self.ContrastLoss(features, labels)\n",
    "        circle_loss = self.CircleLoss(*convert_label_to_similarity(features, labels)) / BS\n",
    "\n",
    "        loss = contrast_loss + ce_loss + circle_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20026910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    margin = 0.75\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=cur_id, \n",
    "            embedding_dim=(cur_id + 1) // 2, \n",
    "            padding_idx=0\n",
    "        )\n",
    "        self.lstm_hidden = 64 # mby it is about vocab_size / 4\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=(cur_id + 1) // 2, \n",
    "            hidden_size=self.lstm_hidden, \n",
    "            num_layers=1, \n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # self.linear = nn.Linear(128 + 64, 256)\n",
    "        \n",
    "        features_num = 128 + 64 + 768 + self.lstm_hidden*2\n",
    "        # output_size = 256\n",
    "        # embedding_size = (features_num + output_size) // 2\n",
    "        \n",
    "        self.stabilizer = nn.Sequential(\n",
    "            nn.Linear(features_num, features_num, bias=False),\n",
    "            nn.Dropout(p=0.1)\n",
    "        )\n",
    "        \n",
    "        embedding_size = 512\n",
    "        self.neck = nn.Sequential(\n",
    "            nn.BatchNorm1d(features_num),\n",
    "            nn.Linear(features_num, embedding_size, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "            nn.Linear(embedding_size, embedding_size, bias=False),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "        )\n",
    "        # self.linear = nn.Linear(embedding_size, output_size)\n",
    "        \n",
    "        # add linear layers to compare between the features of the two images\n",
    "        self.classifier = ClassBlock(\n",
    "            input_dim=embedding_size*2, \n",
    "            class_num=1, \n",
    "            droprate=0, \n",
    "            relu=True,\n",
    "            bnorm=False,\n",
    "            linear=embedding_size\n",
    "        )\n",
    "        \n",
    "        self.criterion = ReIdentificationLossWithClassification()\n",
    "        \n",
    "    def forward(self, x, colors):\n",
    "        colors_emb = self.embedding(colors)\n",
    "        output, (ht, ct) = self.lstm(colors_emb)\n",
    "        # colors_output = output[:, -1, :]\n",
    "        \n",
    "        out_forward = output[:, -1, :self.lstm_hidden]\n",
    "        out_reverse = output[:, 0, self.lstm_hidden:]\n",
    "        colors_output = torch.cat([out_forward, out_reverse], 1)\n",
    "        \n",
    "        # return self.linear(x)\n",
    "        # return self.linear(self.neck(x))\n",
    "        x = torch.cat([x, colors_output], dim=1)\n",
    "        return self.neck(self.stabilizer(x))\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=1e-4, betas=(0.9, 0.999), weight_decay=0.05\n",
    "        )\n",
    "        # optimizer = torch.optim.SGD(self.parameters(), lr=1e-1, momentum=0.9, weight_decay=0.0001)\n",
    "        return (\n",
    "            {\n",
    "                \"optimizer\": optimizer,\n",
    "            },\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # self.log('step', batch_idx, logger=True, on_epoch=True)\n",
    "        x1, colors1, x2, colors2, labels = batch\n",
    "        out1 = self.forward(x1, colors1)\n",
    "        out2 = self.forward(x2, colors2)\n",
    "        \n",
    "        # concatenate both images' features\n",
    "        x = torch.cat((out1, out2), 1)\n",
    "        # pass the concatenation to the linear layers\n",
    "        features, output = self.classifier(x)\n",
    "        loss = 0.5 * self.criterion(features, output, (1 - labels).to(torch.float32))\n",
    "        \n",
    "        # concatenate both images' features\n",
    "        x = torch.cat((out2, out1), 1)\n",
    "        # pass the concatenation to the linear layers\n",
    "        features, output = self.classifier(x)\n",
    "        loss += 0.5 * self.criterion(features, output, (1 - labels).to(torch.float32))\n",
    "        \n",
    "        # fnorm = torch.norm(out1, p=2, dim=1, keepdim=True)\n",
    "        # out1 = out1.div(fnorm.expand_as(out1))\n",
    "        # fnorm = torch.norm(out2, p=2, dim=1, keepdim=True)\n",
    "        # out2 = out2.div(fnorm.expand_as(out2))\n",
    "        \n",
    "        # dists = nn.PairwiseDistance()(out1, out2)\n",
    "        # loss = (labels) * torch.pow(dists, 2) + (1 - labels) * torch.pow(torch.clamp(self.margin - dists, min=0.0), 2)\n",
    "        # loss = torch.mean(loss)\n",
    "        self.log(\"train_loss\", loss, on_step=False, logger=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):        \n",
    "        x1, colors1, x2, colors2, labels = batch\n",
    "        out1 = self.forward(x1, colors1)\n",
    "        out2 = self.forward(x2, colors2)\n",
    "        \n",
    "        # concatenate both images' features\n",
    "        x = torch.cat((out1, out2), 1)\n",
    "        # pass the concatenation to the linear layers\n",
    "        features, output1 = self.classifier(x)\n",
    "        loss = self.criterion(features, output1, (1 - labels).to(torch.float32))\n",
    "        \n",
    "        # concatenate both images' features\n",
    "        x = torch.cat((out2, out1), 1)\n",
    "        # pass the concatenation to the linear layers\n",
    "        features, output2 = self.classifier(x)\n",
    "        \n",
    "        output = (output1 + output2) / 2\n",
    "        \n",
    "        # fnorm = torch.norm(out1, p=2, dim=1, keepdim=True)\n",
    "        # out1 = out1.div(fnorm.expand_as(out1))\n",
    "        # fnorm = torch.norm(out2, p=2, dim=1, keepdim=True)\n",
    "        # out2 = out2.div(fnorm.expand_as(out2))\n",
    "        \n",
    "        # dists = nn.PairwiseDistance()(out1, out2)\n",
    "        # loss = (labels) * torch.pow(dists, 2) + (1 - labels) * torch.pow(torch.clamp(self.margin - dists, min=0.0), 2)\n",
    "        # loss = torch.mean(loss)\n",
    "        self.log(\"val_loss\", loss, logger=False, on_epoch=True, prog_bar=True)   \n",
    "        \n",
    "        try:\n",
    "            auc = roc_auc_score(labels.detach().cpu(), 1 - output.detach().cpu())\n",
    "        except:\n",
    "            auc = 0\n",
    "            \n",
    "        self.log(\"val_auc\", auc, logger=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return val_loader\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx=0):\n",
    "        x1, colors1, x2, colors2, labels = batch\n",
    "        out1 = self.forward(x1, colors1)\n",
    "        out2 = self.forward(x2, colors2)\n",
    "        \n",
    "        # concatenate both images' features\n",
    "        x = torch.cat((out1, out2), 1)\n",
    "        # pass the concatenation to the linear layers\n",
    "        features1, output1 = self.classifier(x)\n",
    "        \n",
    "        # concatenate both images' features\n",
    "        x = torch.cat((out2, out1), 1)\n",
    "        # pass the concatenation to the linear layers\n",
    "        features2, output2 = self.classifier(x)\n",
    "        \n",
    "        fnorm = torch.norm(features1, p=2, dim=1, keepdim=True)\n",
    "        features1 = features1.div(fnorm.expand_as(features1))\n",
    "        fnorm = torch.norm(features2, p=2, dim=1, keepdim=True)\n",
    "        features2 = features2.div(fnorm.expand_as(features2))\n",
    "        \n",
    "        output = (output1 + output2) / 2\n",
    "        features = (features1 + features2) / 2\n",
    "        return torch.cat([features, (1 - output).unsqueeze(-1)], dim=1).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ee41190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(248, 124, padding_idx=0)\n",
       "  (lstm): LSTM(124, 64, batch_first=True, bidirectional=True)\n",
       "  (stabilizer): Sequential(\n",
       "    (0): Linear(in_features=1088, out_features=1088, bias=False)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (neck): Sequential(\n",
       "    (0): BatchNorm1d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=1088, out_features=512, bias=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): ClassBlock(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (add_block): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (classifier): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): ReIdentificationLossWithClassification(\n",
       "    (CircleLoss): CircleLoss(\n",
       "      (soft_plus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (CrossEntropyLoss): BCELoss()\n",
       "    (ContrastLoss): ContrastiveLoss(\n",
       "      (distance): LpDistance()\n",
       "      (reducer): MultipleReducers(\n",
       "        (reducers): ModuleDict(\n",
       "          (pos_loss): AvgNonZeroReducer()\n",
       "          (neg_loss): AvgNonZeroReducer()\n",
       "        )\n",
       "        (default_reducer): MeanReducer()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55ef7cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "Net                                                --\n",
       "├─Embedding: 1-1                                   30,752\n",
       "├─LSTM: 1-2                                        97,280\n",
       "├─Sequential: 1-3                                  --\n",
       "│    └─Linear: 2-1                                 1,183,744\n",
       "│    └─Dropout: 2-2                                --\n",
       "├─Sequential: 1-4                                  --\n",
       "│    └─BatchNorm1d: 2-3                            2,176\n",
       "│    └─Linear: 2-4                                 557,056\n",
       "│    └─ReLU: 2-5                                   --\n",
       "│    └─BatchNorm1d: 2-6                            1,024\n",
       "│    └─Linear: 2-7                                 262,144\n",
       "│    └─BatchNorm1d: 2-8                            1,024\n",
       "├─ClassBlock: 1-5                                  --\n",
       "│    └─Sigmoid: 2-9                                --\n",
       "│    └─Sequential: 2-10                            --\n",
       "│    │    └─Linear: 3-1                            524,800\n",
       "│    │    └─LeakyReLU: 3-2                         --\n",
       "│    └─Linear: 2-11                                513\n",
       "├─ReIdentificationLossWithClassification: 1-6      --\n",
       "│    └─CircleLoss: 2-12                            --\n",
       "│    │    └─Softplus: 3-3                          --\n",
       "│    └─BCELoss: 2-13                               --\n",
       "│    └─ContrastiveLoss: 2-14                       --\n",
       "│    │    └─LpDistance: 3-4                        --\n",
       "│    │    └─MultipleReducers: 3-5                  --\n",
       "===========================================================================\n",
       "Total params: 2,660,513\n",
       "Trainable params: 2,660,513\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "55224dc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 13:53:38,294 [61628] WARNING  py.warnings:109: [JupyterRequire] C:\\Users\\Konder\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "\n",
      "2023-05-23 13:53:38,428 [61628] WARNING  py.warnings:109: [JupyterRequire] C:\\Users\\Konder\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ef68f30b9147d8b32124cb9dfe0641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=False, # CSVLogger('./'),\n",
    "    enable_checkpointing=False,\n",
    "    \n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    profiler='advanced',\n",
    "    precision=32,\n",
    "    check_val_every_n_epoch=1,\n",
    "    max_epochs=10\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9807888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f13a865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 14:09:12,180 [61628] WARNING  py.warnings:109: [JupyterRequire] C:\\Users\\Konder\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e82c8418f54f3eb799dc297714f061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d1f6db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647896305665499"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_pairs.target, np.concatenate([pred.numpy()[:, -1] for pred in test_preds]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90b37a4f",
   "metadata": {},
   "source": [
    "0.8581850684746533 -> 0.8640596471623355 -> 0.8647896305665499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72f60750",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ItemsDataset(train_pairs, train_data)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48a697ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 14:09:36,411 [61628] WARNING  py.warnings:109: [JupyterRequire] C:\\Users\\Konder\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf01265efa3473c9152263dc79d3483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = np.concatenate([pred.numpy() for pred in trainer.predict(model, train_loader)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0c04635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5fb82691b64543a29455a5f9f8baa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_features = np.concatenate([pred.numpy() for pred in trainer.predict(model, val_loader)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c56e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a434e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=features,\n",
    "    label=train_pairs.target,\n",
    ")\n",
    "\n",
    "val_pool = Pool(\n",
    "    data=val_features,\n",
    "    label=val_pairs.target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b04b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'custom_metric': ['AUC'],\n",
    "    'task_type': 'CPU',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "92df1dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035a8d392f834f52926db17e440b53e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b4231dc430>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cb = CatBoostClassifier(**params, random_seed=56)\n",
    "model_cb.fit(train_pool, eval_set=val_pool, verbose=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6a8d9853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716759840727998"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(model_cb.get_evals_result()['validation']['AUC'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "415b3352",
   "metadata": {},
   "source": [
    "0.8702172404565401 -> 0.8716759840727998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "precision, recall, thrs = precision_recall_curve(val_pairs.target, model_cb.predict_proba(val_pool)[:, 1])\n",
    "gt_prec_level_idx = np.where(precision >= 0.75)[0]\n",
    "auc(recall[gt_prec_level_idx], precision[gt_prec_level_idx])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea602623",
   "metadata": {},
   "source": [
    "0.7013227130427283"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1684602749696,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
